{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7bfd94f-68ed-4445-9df0-e7304f614c14",
   "metadata": {},
   "source": [
    "# Working with a new (glider) dataset\n",
    "\n",
    "**Aim:** To look at a new dataset and assess whether you think there may be any problems.\n",
    "\n",
    "**Learning outcomes:** Using what you've learned so far, you will apply this knowledge to a new dataset that you haven't previously encountered.  You will be able to apply your knowledge of sensor response, ocean-knowing-measurements, and python to articulate (and quantify) a possible issue with a dataset.  You will also see an example of how data can be loaded from the internet directly into python.\n",
    "\n",
    "**Data:** You will work with data from [Voice of the Ocean (VOTO)](https://voiceoftheocean.org) collected in the Baltic Sea.  \n",
    "\n",
    "**Directions:** Run the python code step by step, and use it to \n",
    "\n",
    "**Measure of success:** You will have created a python notebook, a netCDF file (*not* added to the git repository) and the 5 figures exported as `*.png` format into your folder; these will be \"commited\" and \"pushed\" to the shared repository, and viewable by everyone.  Additionally, copy your 2 best figures to the `shared_figures/` folder for discussion.  \n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212aa624-bfbb-4151-8e2b-4848ab78ea0f",
   "metadata": {},
   "source": [
    "## Update your environment\n",
    "\n",
    "Your environment will need to contain:\n",
    "- matplotlib\n",
    "- pandas\n",
    "- tqdm\n",
    "- xarrray\n",
    "- cmocean\n",
    "- erddapy\n",
    "- argopy\n",
    "\n",
    "````{note}\n",
    "**If you're using conda to manage your environment:** If these aren't all already in your environment, and you're using `conda` to manage your enviroment, then you can first activate your environment (mine is called `seaocn_env`), then you can run\n",
    "\n",
    "```{python}\n",
    "conda activate seaocn_env\n",
    "conda install --channel conda-forge erddapy argopy cmocean tqdm\n",
    "```\n",
    "\n",
    "**If you aren't using conda:** Then you can simply install the missing packages using your usual routines (may be `pip install erddapy`)\n",
    "\n",
    "\n",
    "You may need to restart your kernal and/or jupyter-lab in order to run with the new packages in your kernel.\n",
    "````\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc4dd6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "from matplotlib import style\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import ast\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "from cmocean import cm as cmo\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac08e0c3-0981-425f-9735-63f629dfb403",
   "metadata": {},
   "source": [
    "## Structure of this python notebook:\n",
    "\n",
    "0. ERDDAP-How to access data\n",
    "1. Åland sea data\n",
    "2. Baltic Inflow\n",
    "3. Hans Storm\n",
    "4. Spring blooms and annual cycle\n",
    "5. Issue with CTD data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dcc57f",
   "metadata": {},
   "source": [
    "# 0. ERDDAP-How to access data \n",
    "We need some functions in untils to download data from ERDDAP\n",
    "You need to have erddap_demo on your computer \n",
    "\n",
    "\n",
    "https://github.com/voto-ocean-knowledge/erddap_demo use git clone to get this on your computer and the adjust the path in order to import all the functions OR simply download `utils.py`.\n",
    "\n",
    "After doing this, I've renamed it on my computer to `erddaputils.py` since `utils.py` is a fairly common package name, and I wanted to make sure I was importing the right file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6ffa0a-4924-42e1-b1e3-0fea000f39aa",
   "metadata": {},
   "source": [
    "Observations portal VOTO https://observations.voiceoftheocean.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e16b8aea-bb01-44d3-aebf-18bfae7a59ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.append('C:\\\\Users\\\\u241346\\\\uni_hamburg\\\\erddap_demo')\n",
    "sys.path.append('/Users/eddifying/Library/Mobile Documents/com~apple~CloudDocs/Work/teaching/SeaOcn-UHH/2024-SeaOcn/05-github/erddap_demo')\n",
    "import erddaputils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fbd8ca-5c4d-4a61-b142-cb8175af2555",
   "metadata": {},
   "source": [
    "## Got an error?\n",
    "\n",
    "If you got an error trying to `import utils` (or after renaming, `import erddaputils`) it may be because the file is not available on your \"path\".  The \"path\" is all the places that python will search for the file.  Update your path using `sys.path.append` OR move `utils.py` (or `erddaputils.py`) to your working directory.  Or, if you haven't already renamed `utils.py` from this github package, then try renaming it since your python may be trying to load a `utils.py` from somewhere else.\n",
    "\n",
    "Note that when you copy it, you will want the actual code (if you open `utils.py` it should look like python code).  If you have a bunch of stuff that looks like HTML (i.e., lines that start with `<` and end with `>`) then you haven't copied the raw file, so try again.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06af9af4-4fb7-464c-908b-29cba8b0651d",
   "metadata": {},
   "source": [
    "## Load the metadata\n",
    "\n",
    "In the next section, we will download the metadata for the VOTO data to find datasets we're interested in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f93b9fc-c52b-4b97-8ae1-ba95eacfa260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 499 datasets\n"
     ]
    }
   ],
   "source": [
    "e = utils.init_erddap()\n",
    "\n",
    "# Fetch dataset list of all dataset existing\n",
    "e.response = \"csv\"\n",
    "e.dataset_id = \"allDatasets\"\n",
    "df_datasets = e.to_pandas(parse_dates=['minTime (UTC)', 'maxTime (UTC)'])\n",
    "\n",
    "print(f\"found {len(df_datasets)} datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb9b4842-21b4-4962-9124-7f158da4ca68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 197/197 [02:23<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# drop the allDatasets row and make the datasetID the index for easier reading\n",
    "df_datasets.set_index(\"datasetID\", inplace=True)\n",
    "df_datasets.drop(\"allDatasets\", inplace=True)\n",
    "\n",
    "# Get only nrt data (near real time) and not delayed as otherwise it would be very long for an intial data exploration\n",
    "df_datasets = df_datasets[df_datasets.index.str[:3] == \"nrt\"]\n",
    "ds_meta = {}\n",
    "for dataset_id in tqdm(df_datasets.index):\n",
    "    ds_meta[dataset_id] = utils.get_meta(dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767daeb5-e879-436b-afbf-908a7c73f07b",
   "metadata": {},
   "source": [
    "```{seealso}\n",
    "Stats to see where data is available and since when: https://observations.voiceoftheocean.org/stats\n",
    "```\n",
    "\n",
    "We just downloaded info on all data so that now we can just find the specific datasets we want based on specific criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1a092c-d4c6-4d9c-9214-e9717881e859",
   "metadata": {},
   "source": [
    "## 1. Download the glider data\n",
    "\n",
    "### Åland sea data\n",
    "\n",
    "Åland Sea or the Sea of Åland is between Sweden and Finland.  It's a narrow strait with  stratification and  currents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f0913a7-f600-4143-b60f-9d4764ac1efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 datasets in Åland: ['nrt_SEA076_M21', 'nrt_SEA076_M24', 'nrt_SEA077_M29', 'nrt_SEA056_M68', 'nrt_SEA078_M24']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of the datasets available in this region\n",
    "name=[]\n",
    "for dataset_id, meta in ds_meta.items():\n",
    "    if meta['deployment_start']>'2023-02-01':\n",
    "        if 'Åland' in meta['basin']:\n",
    "            name.append(dataset_id)\n",
    "print(f'Found {len(name)} datasets in Åland: {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77418be-f149-42a0-9a9d-630ffeee55c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ed7cccb-7f18-47c1-abf0-50fe67af0a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                       | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading nrt_SEA076_M21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eddifying/opt/miniconda3/envs/seaocn_env/lib/python3.8/site-packages/xarray/coding/times.py:250: RuntimeWarning: invalid value encountered in cast\n",
      "  flat_num_dates_ns_int = (flat_num_dates * _NS_PER_TIME_DELTA[delta]).astype(\n",
      " 20%|███████████████████████████████▊                                                                                                                               | 1/5 [00:01<00:05,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading nrt_SEA076_M24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eddifying/opt/miniconda3/envs/seaocn_env/lib/python3.8/site-packages/xarray/coding/times.py:250: RuntimeWarning: invalid value encountered in cast\n",
      "  flat_num_dates_ns_int = (flat_num_dates * _NS_PER_TIME_DELTA[delta]).astype(\n",
      " 40%|███████████████████████████████████████████████████████████████▌                                                                                               | 2/5 [00:03<00:05,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading nrt_SEA077_M29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████████████████████████████████████████████████▍                                                               | 3/5 [00:05<00:03,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading nrt_SEA056_M68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eddifying/opt/miniconda3/envs/seaocn_env/lib/python3.8/site-packages/xarray/coding/times.py:250: RuntimeWarning: invalid value encountered in cast\n",
      "  flat_num_dates_ns_int = (flat_num_dates * _NS_PER_TIME_DELTA[delta]).astype(\n",
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                               | 4/5 [00:06<00:01,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading nrt_SEA078_M24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# Download the glider dataset using the optional argument `nrt_only=True`\n",
    "ds_nrt = utils.download_glider_dataset(name, nrt_only=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d91d453-5395-4d67-81fb-0525ae9861a4",
   "metadata": {},
   "source": [
    "**Near-real time vs delayed-mode data**\n",
    "\n",
    "In this exercise, we will only use near-real time (NRT) data and not delayed mode as it would be way slower otherwise.\n",
    "\n",
    "NRT data from the VOTO gliders generally contain only one file every 3-4 hours (last dive of 2-12 multi-dives).  The CTD data are additionally subsampled to datapoints every 30 seconds (instead of the nominal time interval of 1 second).\n",
    "\n",
    "In deep areas such as the Åland sea, this means that in the NRT files we have approximately every other dive with 30s data. In shallower locations (e.g., the Bornholm basin), we may get one data file every 6-8 dives at 30s time-resolution.\n",
    "\n",
    "In areas with a more complex bathymetry as the Kattegat/Skagerrak area where the glider dives as deep as 200m in the north and as shallow as 40m in the south, we then receive files every 2 to 12 dives for the NRT dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a39a8cf-a05c-41cb-992c-1bac2e9f51e9",
   "metadata": {},
   "source": [
    "### Inspect the data\n",
    "\n",
    "To start with, let's take a look at our data.  We can do this by simply printing to the screen once we know which dataset we're looking for.\n",
    "\n",
    "Compare the two commands, to see what different information/display formats you get:\n",
    "```python\n",
    "ds_nrt['nrt_SEA076_M21']\n",
    "```\n",
    "and then separately,\n",
    "```python\n",
    "print(ds_nrt['nrt_SEA076_M21']\n",
    "```\n",
    "\n",
    "\n",
    "Take a look at the metadata and structure of the data.\n",
    "\n",
    "1. What type are the data?\n",
    "\n",
    "<!--xarray DataArray-->\n",
    "\n",
    "2. What is the \"dimension\", and how long is it?\n",
    "\n",
    "<!--time, and 40510-->\n",
    "\n",
    "3. What is the variable name for temperature?  for salinity?  for depth?\n",
    "\n",
    "<!--temperature, salinity, depth-->\n",
    "\n",
    "Do you get different information if you do the following commands?\n",
    "```python\n",
    "ds_nrt['nrt_SEA076_M21'].keys()\n",
    "list(ds_nrt['nrt_SEA076_M21'].coords)\n",
    "list(ds_nrt['nrt_SEA076_M21'].data_vars)\n",
    "print(ds_nrt['nrt_SEA076_M21'].dims)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e77f28e-096a-4805-8685-de80ebafb4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ds_nrt['nrt_SEA078_M24'].data_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4186c9f-4fc0-477d-97d0-0f60e37579c9",
   "metadata": {},
   "source": [
    "## Concatenate datasets\n",
    "\n",
    "From above, we see that there were five missions of gliders to the Åland Sea.  Rather than dealing with them separately, let's put them all together in a single xarray DataArray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67937ea-a75f-4f1e-8533-f2b4d89eb9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(name)):\n",
    "for i in [0, 1, 4]:\n",
    "        \n",
    "    print(name[i])\n",
    "        #list(ds_nrt[name[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ee0f99-75c4-418d-a915-c6dceabda727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a dataset as empty\n",
    "full_data = []\n",
    "\n",
    "# Cycle through each of the glider datasets listed in `name`\n",
    "#for i in range(len(name)):\n",
    "for i in [4]:\n",
    "    \n",
    "    # For each dataset, append it to the data in full_data (starts empty, and grows)\n",
    "    full_data.append(ds_nrt[name[i]])\n",
    "\n",
    "# Concatenate datasets together along the time dimension\n",
    "full_data = xr.concat(full_data, dim= 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b703fb05-3ad2-40a4-9e61-53e544b78886",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.show_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e9f11e-e15a-420f-afa6-530c4873d910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b79b71f8-6f37-47b9-8a44-f81de8ea9aa7",
   "metadata": {},
   "source": [
    "## 2. Baltic inflow \n",
    "\n",
    "What are Baltic Inflows?\n",
    "\n",
    "The deep water in the Baltic Proper is renewed during specific conditions: when salt water from the Kattegat flows through the Belt and the Sound, and fills in turn the deep areas of the Arkona Basin, the Bornholm Basin, the Eastern Gotland Basin and the western Gotland Basin. They manifest as bottom gravity currents.\n",
    "\n",
    "The Baltic Sea is a very enclosed sea characterized by brakish waters, and salt water only enters through the narrow Danish straits. Water masses change in the upper layers and interlayer, but not near the bottom. The deep waters of the Baltic sea are anoxic. When large amounts of salty water from the North Sea enters the Baltic, this salty and dense oxygen-rich water can replace the anoxic deep water. Such events are called Major Baltic Inflows (MBI) which are a necessary phenomena as they allow oxygen to be replenished in the deepest parts of the Baltic.\n",
    "\n",
    "Detecting Baltic inflows with observations can be a challenge. The short duration of the inflows (2–3 weeks) poses a challenge to traditional ﬁeld measurements.  As a consequence, the BIs are prone to undersampling and difﬁcult to predict. Since regular monitoring cruises in the Baltic Sea typically occur monthly or less frequently, the likelihood of missing or only partially resolving a BI is high.\n",
    "\n",
    "In December, a Baltic inflow was detected. This recent inflow brought 80 km$^3$ of new salty water into the Baltic Sea, making this event a medium size inflow. \n",
    "The last  comparable one was over 5 years ago. The inflow corresponds to 1.6 Gt (1.6 billion t) of salt. This is the first event of this scale since the VOTO observatories started.\n",
    "\n",
    "Estimated that by the beginning of February, the deep water in Bornholm Basin will be exchanged by the new salty inflow.\n",
    "\n",
    "```{seealso}\n",
    "https://news.err.ee/1609206383/rare-saltwater-inflow-in-baltic-sea-could-have-widespread-environmental-impactter.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3cb83e-3a92-4c20-984d-a67643a8b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to find data from the Bornholm Basin (the first basin after the Danish straits) from early December 2023 until now\n",
    "\n",
    "name=[]\n",
    "for dataset_id, meta in ds_meta.items():\n",
    "    if meta['deployment_end']>'2023-12-01':\n",
    "        if 'Bornholm' in meta['basin']:\n",
    "            name.append(dataset_id)\n",
    "print(f'Found {len(name)} datasets in Bornholm: {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b6f427-6461-45e9-a278-51820671d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_nrt = utils.download_glider_dataset(name, nrt_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50036c8-1236-4c66-9ee1-937083446170",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = []\n",
    "for i in range(len(name)):\n",
    "    full_data.append(ds_nrt[name[i]])\n",
    "full_data = xr.concat(full_data, dim= 'time')\n",
    "\n",
    "fig, ax = plt.subplots(4,1,figsize=(20, 15), sharex=True)\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "time=mdates.date2num(full_data.time)\n",
    "t=ax[0].scatter( time,full_data.depth, c=full_data.temperature,s=20, cmap=cmo.thermal, vmin=np.nanpercentile(full_data.temperature, 0.5), vmax=np.nanpercentile(full_data.temperature, 99.5))\n",
    "s=ax[1].scatter( time,full_data.depth, c=full_data.salinity,s=20,cmap=cmo.haline, vmin=np.nanpercentile(full_data.salinity, 0.5), vmax=np.nanpercentile(full_data.salinity, 99.5))\n",
    "d=ax[2].scatter( time,full_data.depth, c=full_data.density, s=20, cmap=cmo.dense, vmin=np.nanpercentile(full_data.density, 0.5), vmax=np.nanpercentile(full_data.density, 99.5))\n",
    "o=ax[3].scatter( time,full_data.depth, c=full_data.oxygen_concentration,cmap=cmo.matter, s=20,vmin=np.nanpercentile(full_data.oxygen_concentration, 0.5), vmax=np.nanpercentile(full_data.oxygen_concentration, 99.5))\n",
    "\n",
    "[a.set_ylim(90,-10) for a in ax]\n",
    "[a.grid() for a in ax]\n",
    "ax[1].xaxis.reset_ticks()\n",
    "ax[1].xaxis.set_major_locator(mdates.WeekdayLocator(byweekday = 1, interval=3))\n",
    "ax[1].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "\n",
    "cbarT=plt.colorbar(t, ax=ax[0], pad = 0.03)\n",
    "cbarT.set_label('Potential \\nTemperature \\n(°C)',labelpad=70, y=0.5, rotation=270,fontsize=18)\n",
    "cbarS=plt.colorbar(s, ax=ax[1], pad = 0.03)\n",
    "cbarS.set_label('Absolute \\nSalinity \\n(g kg$^{-1}$)',labelpad=70, y=0.5, rotation=270,fontsize=18)\n",
    "cbarD=plt.colorbar(d, ax=ax[2], pad = 0.03)\n",
    "cbarD.set_label('Potential \\nDensity \\n(kg m$^{-3}$)',labelpad=70, y=0.5, rotation=270,fontsize=18)\n",
    "cbarO=plt.colorbar(o, ax=ax[3], pad = 0.03)\n",
    "cbarO.set_label('Oxygen \\nconcentration \\n(mmol m$^{-3}$)',labelpad=70, y=0.5, rotation=270,fontsize=18)\n",
    "\n",
    "[a.tick_params(axis='both', which='major', labelsize=18) for a in ax]\n",
    "[a.set_ylabel('Depth (m)',fontsize=18) for a in ax]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22808f3e-7e29-4257-8fa7-71ac1990b4a2",
   "metadata": {},
   "source": [
    "#### Info\n",
    "There are issues with some of the oxygen data and more info can be found here https://observations.voiceoftheocean.org/static/img/reports/Quality_Issue_1_AROD.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02ecf79-4f5d-4a9d-ac55-b511446f60cc",
   "metadata": {},
   "source": [
    "## 3. Hans storm\n",
    "https://www.krisinformation.se/en/hazards-and-risks/disasters-and-incidents/2023/storm-hans\n",
    "\n",
    "https://www.theguardian.com/world/2023/aug/08/storm-hans-causes-havoc-in-norway-with-heaviest-rain-in-25-years-forecast\n",
    "\n",
    "https://www.su.se/department-of-geological-sciences/news/hans-is-the-perfect-storm-globalwarming-contributed-1.664948\n",
    "\n",
    "During the first week on August 2023 a strong storm hit Sweden and Norway causing big floodings and high water level in multiple areas.\n",
    "\n",
    "Is it possible to see the effect of the storm on any of the glider data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bdd2e9-c522-4da7-9b33-afeec897aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We look for all the glider data avaialble from early July to end of August\n",
    "name=[]\n",
    "for dataset_id, meta in ds_meta.items():\n",
    "    if meta['deployment_start']>'2023-07-01':\n",
    "        if meta['deployment_start']<'2023-09-01':\n",
    "            name.append(dataset_id)\n",
    "print(f'Found {len(name)} datasets between July 1st 2023 and September 1st 2023: {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938e39ed-0e97-4581-907d-aa1c38aabe3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_nrt = utils.download_glider_dataset(name, nrt_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfbfed0-2600-4ed0-b113-15404a141d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We want to see where the data  is from and get a bit more info summarized\n",
    "table=pd.DataFrame(columns = ['Glider','Location','Mission','Start_Date'])\n",
    "missions=name\n",
    "dic=ds_nrt\n",
    "table.Mission= range(0,len(missions))\n",
    "    \n",
    "for i in range(len(missions)): \n",
    "    d=dic[missions[i]]\n",
    "    table.loc[i, 'Glider']=f'SEA0{int(d.attrs[\"glider_serial\"])}'\n",
    "    table.loc[i,'Mission']=int(d.attrs[\"deployment_id\"])\n",
    "    table.loc[i, 'Start_Date']=d.attrs[\"deployment_start\"][:10]\n",
    "    table.loc[i,'Location']=d.attrs[\"basin\"]\n",
    "\n",
    "\n",
    "table.sort_values(by=[\"Start_Date\"], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a96db2b-6f2b-47b7-9380-ca158bddc644",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We have data from {len(table.Location.unique())} different sites during this period: {table.Location.unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27da93e3-7d1c-41b2-96bb-36ab8ebf8414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can try to plot data and see if anything is visible in any of the 4 areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e22bca-bdad-4610-8175-1707d85ed36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sel_data(basin='Bornholm', date_start='2023-07-01', date_end='2023-09-01', rectangle=True,  delayed = False):\n",
    "    \n",
    "    name=[]\n",
    "    for dataset_id, meta in ds_meta.items():\n",
    "        if meta['deployment_start']>date_start:\n",
    "            if meta['deployment_start']<date_end:\n",
    "                if basin in meta['basin']:\n",
    "                    if 'SAMBA' in meta['project']:\n",
    "                        if delayed == True:\n",
    "                            name.append(f'delayed{dataset_id[3:]}')\n",
    "                        else:\n",
    "                            name.append(dataset_id)\n",
    "    \n",
    "        \n",
    "    ds_nrt = utils.download_glider_dataset(name, nrt_only=False)\n",
    "    \n",
    "    full_data = []\n",
    "    for i in range(len(name)):\n",
    "        full_data.append(ds_nrt[name[i]])\n",
    "    full_data = xr.concat(full_data, dim= 'time')\n",
    "    \n",
    "    fig, ax = plt.subplots(5,1,figsize=(20, 15), sharex=True)\n",
    "    \n",
    "    time=mdates.date2num(full_data.time)\n",
    "    t=ax[0].scatter( time,full_data.depth, c=full_data.temperature,s=20, cmap=cmo.thermal, vmin=np.nanpercentile(full_data.temperature, 0.5), vmax=np.nanpercentile(full_data.temperature, 99.5))\n",
    "    s=ax[1].scatter( time,full_data.depth, c=full_data.salinity,s=20,cmap=cmo.haline, vmin=np.nanpercentile(full_data.salinity, 0.5), vmax=np.nanpercentile(full_data.salinity, 99.5))\n",
    "    d=ax[2].scatter( time,full_data.depth, c=full_data.density, s=20, cmap=cmo.dense, vmin=np.nanpercentile(full_data.density, 0.5), vmax=np.nanpercentile(full_data.density, 99.5))\n",
    "    o=ax[3].scatter( time,full_data.depth, c=full_data.oxygen_concentration, s=20,vmin=np.nanpercentile(full_data.oxygen_concentration, 0.5), vmax=np.nanpercentile(full_data.oxygen_concentration, 99.5))\n",
    "    c=ax[4].scatter( time,full_data.depth, c=full_data.chlorophyll, s=20, cmap=cmo.algae, vmin=np.nanpercentile(full_data.chlorophyll, 0.5), vmax=np.nanpercentile(full_data.chlorophyll, 99.5))\n",
    "    \n",
    "    # Highlight storm period\n",
    "    if rectangle:\n",
    "        for a in ax: \n",
    "            rect = patches.Rectangle((int(mdates.date2num(['2023-08-07'])[0]), int(full_data.depth.max())), 5, 3, linewidth=5, edgecolor='r', facecolor='red', fill='red')\n",
    "            a.add_patch(rect) \n",
    "    \n",
    "    [a.set_ylim(int(full_data.depth.max())+5,-10) for a in ax]\n",
    "    [a.grid() for a in ax]\n",
    "\n",
    "    ax[4].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    ax[4].locator_params(axis='x', nbins=8) \n",
    "    \n",
    "    cbarT=plt.colorbar(t, ax=ax[0], pad = 0.03)\n",
    "    cbarT.set_label('Potential \\nTemperature \\n(°C)',labelpad=70, y=0.5, rotation=270,fontsize=18)\n",
    "    cbarS=plt.colorbar(s, ax=ax[1], pad = 0.03)\n",
    "    cbarS.set_label('Absolute \\nSalinity \\n(g kg$^{-1}$)',labelpad=70, y=0.5, rotation=270,fontsize=18)\n",
    "    cbarD=plt.colorbar(d, ax=ax[2], pad = 0.03)\n",
    "    cbarD.set_label('Potential \\nDensity \\n(kg m$^{-3}$)',labelpad=70, y=0.5, rotation=270,fontsize=18)\n",
    "    cbarO=plt.colorbar(o, ax=ax[3], pad = 0.03)\n",
    "    cbarO.set_label('Oxygen \\nconcentration \\n(mmol m$^{-3}$)',labelpad=70, y=0.5, rotation=270,fontsize=18)\n",
    "    cbarC=plt.colorbar(c, ax=ax[4], pad = 0.03)\n",
    "    cbarC.set_label('Chlorophyll \\n(mg m$^{-3}$)',labelpad=70, y=0.5, rotation=270,fontsize=18)\n",
    "    \n",
    "    [a.tick_params(axis='both', which='major', labelsize=18) for a in ax]\n",
    "    [a.set_ylabel('Depth (m)',fontsize=18) for a in ax]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5acd839-d8a0-490a-b28d-ed21e8799af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sel_data(basin='Bornholm',date_start='2023-07-01', date_end='2023-09-01',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9852ebe7-7645-4c58-97d5-f022b6e08e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sel_data(basin='Eastern Gotland',date_start='2023-07-01', date_end='2023-09-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a336b09-ae9e-40b1-9611-e2e81d7696a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sel_data(basin='Western Gotland',date_start='2023-07-01', date_end='2023-09-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f714ee-22ec-4abd-acd8-6cc31b1e2647",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sel_data(basin='Kattegat', date_start='2023-07-01', date_end='2023-09-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4282ec3-d329-4818-9578-c754a0b30672",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Temperature and salinity for Western Gotland looks weird, let#s check if we see issues in the delayed mode data as well\n",
    "plot_sel_data(basin='Western Gotland',date_start='2023-07-01', date_end='2023-09-01', delayed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c33804e-e869-43fe-82c9-8f30ec7e6a74",
   "metadata": {},
   "source": [
    "## 4. Spring blooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0dbe1c-7e3f-4ac0-8c27-4d2ab901d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sel_data(basin='Bornholm',date_start='2023-01-01', date_end='2024-01-01',rectangle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b72087-6b44-4b23-880c-8196288bdfe8",
   "metadata": {},
   "source": [
    "#### Info\n",
    "There are issues with some of the oxygen data and more info can be found here https://observations.voiceoftheocean.org/static/img/reports/Quality_Issue_1_AROD.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aa6547-0601-4080-b203-881a8b0adf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sel_data(basin='Eastern Gotland',date_start='2023-01-01', date_end='2024-01-01',rectangle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a4a4f-0911-4f77-bf99-1a014d71ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sel_data(basin='Skagerrak',date_start='2023-01-01', date_end='2024-01-01',rectangle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dd58d3-292a-4140-a47b-a24ce91e59ef",
   "metadata": {},
   "source": [
    "## 5. Specific data with issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee23d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEA070 with pumped SeaBird CTD\n",
    "name = ['delayed_SEA070_M15', 'delayed_SEA070_M15']\n",
    "ds_delayed = utils.download_glider_dataset(name, nrt_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b12b5-2b57-442c-97c9-d445edc57533",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = []\n",
    "for i in range(len(name)):\n",
    "    full_data.append(ds_delayed[name[i]])\n",
    "full_data = xr.concat(full_data, dim= 'time')\n",
    "\n",
    "fig, ax = plt.subplots(5,1,figsize=(20, 15), sharex=True)\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "time=mdates.date2num(full_data.time)\n",
    "t=ax[0].scatter( time,full_data.depth, c=full_data.temperature,s=20, cmap=cmo.thermal, vmin=np.nanpercentile(full_data.temperature, 0.5), vmax=np.nanpercentile(full_data.temperature, 99.5))\n",
    "s=ax[1].scatter( time,full_data.depth, c=full_data.salinity,s=20,cmap=cmo.haline, vmin=np.nanpercentile(full_data.salinity, 0.5), vmax=np.nanpercentile(full_data.salinity, 99.5))\n",
    "d=ax[2].scatter( time,full_data.depth, c=full_data.density, s=20, cmap=cmo.dense, vmin=np.nanpercentile(full_data.density, 0.5), vmax=np.nanpercentile(full_data.density, 99.5))\n",
    "o=ax[3].scatter( time,full_data.depth, c=full_data.oxygen_frequency, s=20,vmin=np.nanpercentile(full_data.oxygen_frequency, 0.5), vmax=np.nanpercentile(full_data.oxygen_frequency, 99.5))\n",
    "c=ax[4].scatter( time,full_data.depth, c=full_data.chlorophyll, s=20, cmap=cmo.algae, vmin=np.nanpercentile(full_data.chlorophyll, 0.5), vmax=np.nanpercentile(full_data.chlorophyll, 99.5))\n",
    "    \n",
    "[a.set_ylim(int(full_data.depth.max()+10),-10) for a in ax]\n",
    "[a.grid() for a in ax]\n",
    "ax[1].xaxis.reset_ticks()\n",
    "ax[1].xaxis.set_major_locator(mdates.WeekdayLocator(byweekday = 1, interval=3))\n",
    "ax[1].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "\n",
    "cbarT=plt.colorbar(t, ax=ax[0], pad = 0.03)\n",
    "cbarT.set_label('Potential \\nTemperature \\n(°C)',labelpad=70, y=0.5, rotation=270,fontsize=18)\n",
    "cbarS=plt.colorbar(s, ax=ax[1], pad = 0.03)\n",
    "cbarS.set_label('Absolute \\nSalinity \\n(g kg$^{-1}$)',labelpad=70, y=0.5, rotation=270,fontsize=18)\n",
    "cbarD=plt.colorbar(d, ax=ax[2], pad = 0.03)\n",
    "cbarD.set_label('Potential \\nDensity \\n(kg m$^{-3}$)',labelpad=70, y=0.5, rotation=270,fontsize=18)\n",
    "cbarO=plt.colorbar(o, ax=ax[3], pad = 0.03)\n",
    "cbarO.set_label('Oxygen \\nconcentration \\n(mmol m$^{-3}$)',labelpad=70, y=0.5, rotation=270,fontsize=18)\n",
    "cbarC=plt.colorbar(c, ax=ax[4], pad = 0.03)\n",
    "cbarC.set_label('Chlorophyll \\n(mg m$^{-3}$)',labelpad=70, y=0.5, rotation=270,fontsize=18)\n",
    "\n",
    "[a.tick_params(axis='both', which='major', labelsize=18) for a in ax]\n",
    "[a.set_ylabel('Depth (m)',fontsize=18) for a in ax]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8462f4-028e-4ea5-ace1-191a540fb809",
   "metadata": {},
   "source": [
    "## This is all raw data and many adjustments have to be applied and various issues soruces should be considered\n",
    "* Thermal hysteresis\n",
    "* Quenching corrections\n",
    "* Calibration (ex. optics dark count correction and scaling factor correction, oxygen calibration etc..)\n",
    "* Electrical spikes\n",
    "* Outliers\n",
    "* Sensor failure\n",
    "* Specific sensor issues (FLBBPC issues, FLBBCD issues, AROD and CODA issues)\n",
    "* \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:seaocn_env] *",
   "language": "python",
   "name": "conda-env-seaocn_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
