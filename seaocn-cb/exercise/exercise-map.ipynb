{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3068a6a-bb7e-412f-8aff-875afa0543cb",
   "metadata": {},
   "source": [
    "# Exercise 3 - Exploring map projections\n",
    "\n",
    "\n",
    "**Aim:** To create a map of data from reanalysis heat fluxes.\n",
    "\n",
    "**Data:** You will need to download files from [ICDC](https://www.cen.uni-hamburg.de/en/icdc/data/atmosphere/reanalysis-atmosphere/ncep.html).  We will be using NCEP Reanalysis heat fluxes at the ocean surface, and you will need one snapshot of sensible heat flux, latex heat flux, net shortwave and net longwave radiation flux.  \n",
    "\n",
    "**Directions:** Create an `*.ipynb` and 3 figures: once using Matplotlib, and two using pyGMT with different projections.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2019c0dd-b5e8-44cd-b840-7610db220bf5",
   "metadata": {},
   "source": [
    "## Create a notebook \n",
    "\n",
    "1. Create an `*.ipynb` containing the commands for this assignment, or copy this file.  \n",
    "    \n",
    "    ```{admonition} File naming convention\n",
    "    Name your python notebook something useful `ex<X>-<Lastname>-<slug>-seaocn.ipynb` where you replace `<X>` with the exercise number and `<slug>` with the short slug to name the topic, and `<Lastname>` with your last name.\n",
    "\n",
    "    Figures should be named something like `ex<X>fig<Y>-<Lastname>-<slug>-seaocn.png` where you replace `<X>` with the exercise number, `<Y>` with the figure number, and `<Lastname>` with your last name.\n",
    "    ```\n",
    "\n",
    "2. Import necessary packages.  \n",
    "\n",
    "\n",
    "\n",
    "    For example, `matplotlib` and `pandas` and `numpy` and `xarray`.  You may also need\n",
    "    ```{python}\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import xarray as xr\n",
    "    from datetime import datetime\n",
    "    ```\n",
    "    If you are missing any of these packages, please refer to [Resources: Python](../resource/python).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a841f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "\n",
    "# Some extra colormaps\n",
    "import cmocean\n",
    "\n",
    "# Fancy but non-intuitive\n",
    "import pygmt\n",
    "\n",
    "# Cartopy\n",
    "import cartopy\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.mpl.ticker as cticker\n",
    "from cartopy.mpl.ticker import LatitudeFormatter, LongitudeFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a44db0-ccfc-4bf5-87bf-0e09b9010344",
   "metadata": {},
   "source": [
    "### Downloading data\n",
    "\n",
    "3. Download some data.  First decide what year you'd like to work with; anything from 1948 to 2023 is fine.  Then navigate to each of the 4 components of surface heat fluxes on the ICDC page [https://icdc.cen.uni-hamburg.de/thredds-int/catalog/dataicdc/reanalyses/ncep_reanalysis1/DATA/sensible_heat_flux/catalog.html](https://icdc.cen.uni-hamburg.de/thredds-int/catalog/dataicdc/reanalyses/ncep_reanalysis1/DATA/sensible_heat_flux/catalog.html).  Download **one of each file** for your chosen year.  Note that these files are about 30 mb each.\n",
    "\n",
    "\n",
    "```{tip}\n",
    "Double check when you commit that these files are not getting committed to the gitlab repository.\n",
    "```\n",
    "\n",
    "6. Make a basic exploration. How big are the data?  What are the coordinates?  \n",
    "\n",
    "- To make the code easier to change, we'll recommend building the filename out of components.  This gives you the possibility later of downloading a different year and only updating part of the code.\n",
    "\n",
    "    ```{python}\n",
    "    myyear = 2001\n",
    "    filepath = 'data/' # If you have a file folder containing data\n",
    "    fpre = ['lhtfl', 'nswrs']  # Add to this all the names of the variables\n",
    "    fpost = '.sfc.gauss.' + str(myyear) + '.nc'\n",
    "    ```\n",
    "    \n",
    "    This will give us a filename once we contenate together the various pieces:\n",
    "    ```{python}\n",
    "    fname = filepath + fpre[0] + fpost\n",
    "    ```\n",
    "\n",
    "- Now you can do this one after another, where you call each of the 4 choices in `fpre` separately as `fpre[0]`, `fpre[1]`, and so on.  Or you can use a loop.\n",
    "\n",
    "    In python, one of the basic loop types is a `for-do` loop.\n",
    "    \n",
    "    ```{seealso}\n",
    "    About for-do loops: https://www.w3schools.com/python/python_for_loops.asp\n",
    "    ```\n",
    "\n",
    "    Here, we'll use a loop that goes through a simple vector which has the length the same as the length of `fpre`.  First check what is the length of `fpre`?\n",
    "\n",
    "    ```{python}\n",
    "    print(len(fpre))\n",
    "    ```\n",
    "    It should be 4.  If it's not, then go back and edit where you define the list `fpre`.   Verify that it is indeed of type `list` by doing\n",
    "    ```{python}\n",
    "    print(type(fpre))\n",
    "    ```\n",
    "\n",
    "- Now construct your for-do loop which builds the different variable names\n",
    "\n",
    "    ```{python}\n",
    "    for i in range(len(fpre)):\n",
    "        fname = filepath + fpre[i] + fpost\n",
    "        print(fname)\n",
    "    ```\n",
    "\n",
    "    Check that it is correctly producing the name of a file.\n",
    "\n",
    "- Load the data.  If you had a single filename correctly named in the string `fname`, then you could use `xr.open_dataset(fname)`.  For example\n",
    "\n",
    "    ```{python}\n",
    "    mydata = xr.open_dataset(fname)\n",
    "    ```\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5736636d-c6cf-4e6d-9167-8451b9d40e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007faaf-35c7-4d50-a4cc-65b491017fbc",
   "metadata": {},
   "source": [
    "### Loading all variables into a single `dictionary`\n",
    "\n",
    "Python has a variable type called a \"dictionary\" which is used to store \"key - value\" pairs.\n",
    "\n",
    "```{seealso}\n",
    "Python dictionary: https://www.w3schools.com/python/python_dictionaries.asp\n",
    "```\n",
    "\n",
    "In the simple website example in the \"seealso\", these are pairs of strings, or numbers, or arrays.  In our case here, we can create a dictionary of xarray datasets.\n",
    "\n",
    "In your code above, replace the left side of the equation where you load the dataset (i.e., where you use the command `xr.open_dataset`) with\n",
    "```{python}\n",
    "flux_components[fpre[i]] = xr.open_dataset(fname)\n",
    "```\n",
    "\n",
    "Once you have done this, you can check out the data within the dictionary using the following commands.\n",
    "\n",
    "The first one, `print(flux_components['lhtfl'].lhtfl.shape)` will tell you how big the dataset of latent heat flux is (x, y and z directions).\n",
    "\n",
    "The second looks more like an xarray dataset that you're familiar with (`print(flux_components['lhtfl']`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c953b55d-5daf-4e38-bb03-f8e2a2a27848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out how big the datasets are\n",
    "print(flux_components['lhtfl'].lhtfl.shape)\n",
    "print(flux_components['lhtfl'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3cfab9-dfad-4160-b6d1-bec7eb73ab28",
   "metadata": {},
   "source": [
    "### Merge into a single xarray dataset\n",
    "\n",
    "The dictionary of xarray datasets was kind of useful, but with xarray we don't need to bother using a dictionary to store the data.  Instead, we can use the command `xr.merge` to combine the similar datatypes (same coordinates, same dimensions, but different variables: latent, sensible heat flux, and shortwave and longwave radiation).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aec638-c3da-4100-af56-14eeab71bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the datasets using xr.merged\n",
    "all_flux = xr.merge([\n",
    "    flux_components['lhtfl'],\n",
    "    flux_components['shtfl'],\n",
    "    flux_components['nswrs'],\n",
    "    flux_components['nlwrs']])\n",
    "print(all_flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c6edce-6ce0-4077-abbd-88f7ae2a4d79",
   "metadata": {},
   "source": [
    "### Plot with `matplotlib`\n",
    "\n",
    "Now we'd like to take a look at the data for a single snapshot (a single time).  The example code below will choose the very first frame (where the time index is 0), and plot the latent heat flux.  Update the code in order to plot four fields (sensible, latent, shortwave and longwave)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549a898d-73a9-4d7a-a45f-433e7fc29eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the fields\n",
    "# choose the index of the snapshot to show\n",
    "itime = 0\n",
    "map1 = all_flux.lhtfl[itime,:,:]\n",
    "\n",
    "fig, axs = plt.subplots(2,2)\n",
    "axs[0,0].contourf(data1.lon, data1.lat, map1, cmap='RdYlBu')\n",
    "axs[0,0].set_title('Latent heat flux')\n",
    "axs[0,0].set_ylabel('Latitude')\n",
    "\n",
    "# Cumbersome date time to string\n",
    "d = data1.time[itime].dt.strftime('%Y.%m.%d').values\n",
    "fig.suptitle('NCEP Reanalysis \\n' + d)\n",
    "\n",
    "fig.savefig('fig1-Lastname-heatflux.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b822aada-1465-41d1-a855-035726956a69",
   "metadata": {},
   "source": [
    "## Making a seasonal  average\n",
    "\n",
    "1. Now we're going to use some of the fancier features of the xarray data construction.  We'd like to make an average over **1 January through 31 March for your chosen year**.   Since we've stored the data all in a single `xarray` dataset, we can calculate the mean with one line of code.  \n",
    "\n",
    "    An annual average would be computed as:\n",
    "    ```{python}\n",
    "    ann_flux = all_flux.mean(dim='time', keep_attrs=True)\n",
    "    ```\n",
    "\n",
    "2. What happens if you don't include the `keep_attrs=True` option?  Try deleting it and see what changes.\n",
    "\n",
    "3. How can you tell Python to only average over a certain time range, or specified months?\n",
    "\n",
    "\n",
    "```{seealso}\n",
    "- Averaging `xarray` datasets all at once. [https://docs.xarray.dev/en/stable/generated/xarray.Dataset.mean.html](https://docs.xarray.dev/en/stable/generated/xarray.Dataset.mean.html)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15581c8-9b52-4797-85a1-d7f083fb21b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat this, but make an average over Jan - March\n",
    "ann_flux = all_flux.mean(dim='time', keep_attrs=True)\n",
    "print(ann_flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d6e927-80e1-4fb8-a828-71f3ba7cfdda",
   "metadata": {},
   "source": [
    "### Fig 2. Update figure for winter\n",
    "\n",
    "Single-day snapshots of heat fluxes can be hard to read.  Let's repeat the plot above with the winter (January - March) averages instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2505f54b-6582-40e1-bcba-5d8f1c365d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the fields\n",
    "# choose the index of the snapshot to show\n",
    "\n",
    "fig, axs = plt.subplots(2,2)\n",
    "axs[0,0].contourf(data1.lon, data1.lat, myflux.lhtfl[:,:], cmap='RdYlBu')\n",
    "axs[0,0].set_title('Latent heat flux')\n",
    "axs[0,0].set_ylabel('Latitude')\n",
    "\n",
    "# Cumbersome date time to string - Since we've done the annual average, we only need one year.\n",
    "d = data1.time[itime].dt.strftime('%Y').values\n",
    "fig.suptitle('NCEP Reanalysis \\n' + d)\n",
    "\n",
    "fig.savefig('fig2-lastname-matplotlib.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ab293d-466e-45a7-a325-db84d669da9d",
   "metadata": {},
   "source": [
    "## Fig 3. Using `cartopy`\n",
    "\n",
    "Here you'll see how to add coastlines to the maps, and maybe switch up your map projection using `cartopy`.\n",
    "\n",
    "- Available map projections: [https://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html](https://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html)\n",
    "\n",
    "\n",
    "```{seealso}\n",
    "https://geohackweek.github.io/visualization/03-cartopy/\n",
    "```\n",
    "The code below only partially works.  The y-axis labels are broken, and it currently plots the daily snapshot rather than the annual mean.  Try to update the plot to fix the y axis labels and to move the top row of figures closer to the bottom row.\n",
    "\n",
    "- Explore how to fix the labels on Cartopy maps: [https://scitools.org.uk/cartopy/docs/latest/gallery/gridlines_and_labels/tick_labels.html](https://scitools.org.uk/cartopy/docs/latest/gallery/gridlines_and_labels/tick_labels.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1740385-616b-4fcd-b7f4-ba617bbb6885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some parameters for the map\n",
    "nrows=2\n",
    "ncols=2\n",
    "itime = 0\n",
    "myprojection = ccrs.AlbersEqualArea()\n",
    "myprojection = ccrs.Mercator()\n",
    "myprojection = ccrs.PlateCarree()\n",
    "\n",
    "# Initialise the map with the projection above\n",
    "fig, axs = plt.subplots(nrows=nrows,ncols=ncols,\n",
    "                        subplot_kw={'projection': myprojection},\n",
    "                        figsize=(11,8.5))\n",
    "\n",
    "# axs is a 2 dimensional array of `GeoAxes`.  \n",
    "# We will flatten it into a 1-D array.\n",
    "# This helps when plotting using a for-loop.\n",
    "axs=axs.flatten()\n",
    "\n",
    "# Loop through fluxes\n",
    "for i in range(len(fpre)):\n",
    "    # Select the flux to load\n",
    "    data1 = flux_components[fpre[i]]\n",
    "    map1 = data1[fpre[i]][itime,:,:]\n",
    "    axs[i].contourf(data1.lon, data1.lat, map1, cmap='RdYlBu', transform=cartopy.crs.PlateCarree())\n",
    "    axs[i].coastlines()               # plot some data on them\n",
    "    axs[i].set_title(fpre[i])                        # label it\n",
    "    axs[i].add_feature(cfeature.COASTLINE)\n",
    "\n",
    "    # Longitude labels\n",
    "    axs[i].set_xticks(np.arange(-180,181,90), crs=cartopy.crs.PlateCarree())\n",
    "    lon_formatter = cticker.LongitudeFormatter()\n",
    "    axs[i].xaxis.set_major_formatter(lon_formatter)\n",
    "\n",
    "    # Latitude labels\n",
    "    axs[i].set_yticks(np.arange(-90,91,30), crs=ccrs.Mercator())\n",
    "\n",
    "fig.savefig('fig3-lastname-cartopy.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463e564e-f273-4086-973d-94a754f6d7ab",
   "metadata": {},
   "source": [
    "## Fig 4. Using `pyGMT` \n",
    "\n",
    "PyGMT is especially good for geophysical quantities (and geophysics). However, the formatting language looks a little strange if you're used to `matplotlib`.\n",
    "\n",
    "```{seealso}\n",
    "PyGMT tutorials: [https://www.pygmt.org/latest/tutorials/index.html](https://www.pygmt.org/latest/tutorials/index.html)\n",
    "```\n",
    "\n",
    "- Projections availble: [https://www.pygmt.org/dev/projections/index.html](https://www.pygmt.org/dev/projections/index.html)\n",
    "- Colormaps available: [https://docs.generic-mapping-tools.org/6.5/reference/cpts.html](https://docs.generic-mapping-tools.org/6.5/reference/cpts.html)\n",
    "\n",
    "### Update the code below\n",
    "\n",
    "- Experiment with a different font color or size\n",
    "- Try different figure sizes\n",
    "- Can you change the projection?  Note that the formatting of projection strings is strange.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff83a41-cae6-4f1a-94ff-744eaf0bcbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some sample code.\n",
    "fig = pygmt.Figure()\n",
    "\n",
    "with pygmt.config(FONT_ANNOT_PRIMARY=\"20p,Helvetica,blue\", FONT_LABEL=\"15p,Helvetica,red\"):\n",
    "    with fig.subplot(nrows=2, ncols=2,  figsize=(\"30c\", \"22c\"), sharex=\"b\", sharey=\"l\", margins=\"1c\"):\n",
    "        for i in range(len(fpre)):\n",
    "            fname = filepath + fpre[i] + fpost\n",
    "            grid = fname + '?' + fpre[i]\n",
    "\n",
    "            \n",
    "            with fig.set_panel(panel=i):  # sets the current panel\n",
    "                fig.basemap(\n",
    "                    region=\"g\",\n",
    "                    projection=\"Cyl_stere/150/-20/?\",\n",
    "                    frame=['WSne+t'+fpre[i], \"xa90\", \"ya30\"],\n",
    "                )\n",
    "                fig.grdimage(\n",
    "                    grid=grid,\n",
    "                    cmap='no_green',\n",
    "                )\n",
    "                fig.coast(shorelines=\"1/0.5p,black\")\n",
    "                #fig.colorbar(frame=['x+l' +fpre[i], \"y+lW/m@+2@+\"])\n",
    "\n",
    "fig.show()\n",
    "fig.savefig('fig4-lastname-pygmt.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6213379b-97c2-47e6-9bc4-6fedf332b6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
